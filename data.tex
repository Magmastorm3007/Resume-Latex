\documentclass[10pt]{resume}
\usepackage[left=0.5in,top=0.35in,right=0.5in,bottom=0.35in]{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\setlist[itemize]{noitemsep, topsep=2pt, left=0.8em}

\setlength{\parskip}{2pt}
\setlength{\parsep}{0pt}
\renewcommand{\baselinestretch}{1.0}

\name{Shashwat Nath}
\address{shashwatnath30@gmail.com \quad +91 8810614670 \quad Delhi, India}
\address{\href{https://live-portfolio-3d.onrender.com}{Portfolio} \quad
\href{https://github.com/Magmastorm3007}{GitHub} \quad
\href{https://leetcode.com/u/user5454Z}{LeetCode} \quad
\href{https://magmastorm.hashnode.dev}{Blog}}

\begin{document}
\small

\begin{rSection}{SUMMARY}
Data Engineer with \textbf{1+} years of experience in designing scalable ETL/data pipelines, backend services, and production-grade applications in agile teams using PySpark, SQL and AWS. Strong foundation in algorithms, cloud infrastructure, and distributed systems.
\end{rSection}

\begin{rSection}{EDUCATION}
\textbf{B.Tech, Information Technology} \hfill Manipal University Jaipur \\
\textbf{2020--2024} \quad CGPA: \textbf{8.53}
\end{rSection}

\begin{rSection}{EXPERIENCE}
\textbf{Data Engineer}, LTIMindTree \hfill Dec \textbf{2024}–Present, Bengaluru
\begin{itemize}
  \item Designed and automated data pipelines using \textbf{Apache Airflow}, leveraging DAG scheduling, retries, Operators, and Task Instances to orchestrate workflows across multiple data sources.
  \item Integrated \textbf{PySpark job submissions}, S3 hooks, and the boto3 library to manage large-scale data movement with IAM roles and policies on AWS EC2 instances.
  \item Migrated \textbf{50+} legacy ETL workflows from on-premise Informatica systems to \textbf{AWS Glue (PySpark)}, modernizing data pipelines for a leading American Insurance client and reducing monthly server costs by \textbf{38\%}.
  \item Built \textbf{serverless pipelines} using AWS Lambda and Step Functions (Python \& Node.js) for data transformation and orchestration, cutting software licensing costs by \textbf{20\%} and streamlining event-driven data delivery.
  \item Optimized AWS Glue jobs by tuning \textbf{Spark configurations} and partitioning strategies, achieving \textbf{30–50\%} faster execution times compared to baseline while handling terabyte-scale datasets.
  \item Monitored and maintained \textbf{100+} financial tables using Splunk and Stonebranch, implementing \textbf{automated alerts and daily compliance reports} to meet strict regulatory requirements.
  \item Enhanced observability and debugging by integrating AWS \textbf{CloudFormation logs into Splunk dashboards}, enabling real-time tracking of infrastructure deployments and pipeline execution health.
  \item Implemented \textbf{data quality and code coverage checks} with Pytest and SonarQube, ensuring \textbf{75\%+} coverage across ETL pipelines and backend Lambda services to reduce production incidents and improve system reliability.
  \item Collaborated with cross-functional teams to deliver production-ready data services, following Agile/Scrum best practices and CI/CD pipelines.
  \item Documented workflows and provided knowledge transfer to client teams and help onboard P1 grade engineers in the team.
\end{itemize}
\end{rSection}

\begin{rSection}{RESEARCH}
\begin{itemize}
  \item Published paper with \textbf{Springer}, presenting peer study and analysis of Breast Cancer Detection Algorithms with Machine Learning and AI algorithms including SVM,KNN and Random Forest, Link: \href{https://link.springer.com/chapter/10.1007/978-981-19-4990-6_57}{https://link.springer.com/chapter/10.1007/978-981-19-4990-6\_57}. It was considered under Best Paper Awards at the Conference.
  \item  Research on \textbf{Hybrid Genetic Algorithm for Whale and Gravitational Search Optimization} (Ongoing), exploring optimization techniques for alternative feature selection in Data Analysis and AI/ML modelling.
\end{itemize}
\end{rSection}

\begin{rSection}{CERTIFICATIONS}
\begin{itemize}
  \item \textbf{AWS Certified Developer – Associate:} Ongoing certification to become proficient in developing, deploying, and monitoring native cloud applications, creating event-driven data pipelines to interact with various AWS services.
  \item \textbf{Oracle Database Foundations:} Covered SQL programming, relational data modeling, and performance-tuned database design through extensive lab practice.
  \item \textbf{Red Hat System Administration II:} Hands-on Linux server administration, shell scripting, system monitoring, and enterprise environment configuration.
\end{itemize}
\end{rSection}

\begin{rSection}{SKILLS}
\textbf{Languages:} Python, C++ \\
\textbf{Data Engineering:} PySpark, SQL, PostgreSQL, ETL, AWS Glue, Lambda, Step Functions, S3, Airflow \\
\textbf{Cloud:} AWS (EC2, IAM, CloudFormation, CloudWatch) \\
\textbf{Other Tools:} Docker,Kubernetes, Git, Splunk, Stonebranch, SonarQube, Pytest,Node
\end{rSection}

\end{document}
